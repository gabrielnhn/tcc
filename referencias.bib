% % Modelos de referências em BibTeX

% % % ATENCAO:
% % %
% % % - para preservar as maiúsculas em siglas nos títulos, use {...}.

@inproceedings{gaze360_2019,
    author = {Petr Kellnhofer and Adria Recasens and Simon Stent and Wojciech Matusik and Antonio Torralba},
    title = {Gaze360: Physically Unconstrained Gaze Estimation in the Wild},
    booktitle = {IEEE International Conference on Computer Vision (ICCV)},
    month = {October},
    year = {2019}
}


@inproceedings{ijcai2020-689,
  title     = {Human Gaze Assisted Artificial Intelligence: A Review},
  author    = {Zhang, Ruohan and Saran, Akanksha and Liu, Bo and Zhu, Yifeng and Guo, Sihang and Niekum, Scott and Ballard, Dana and Hayhoe, Mary},
  booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on
               Artificial Intelligence, {IJCAI-20}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Christian Bessiere},
  pages     = {4951--4958},
  year      = {2020},
  month     = {7},
  note      = {Survey track},
  doi       = {10.24963/ijcai.2020/689},
  url       = {https://doi.org/10.24963/ijcai.2020/689},
}

@ARTICLE{Massaro2012-jx,
  title    = "When art moves the eyes: a behavioral and eye-tracking study",
  author   = "Massaro, Davide and Savazzi, Federica and Di Dio, Cinzia and
              Freedberg, David and Gallese, Vittorio and Gilli, Gabriella and
              Marchetti, Antonella",
  abstract = "The aim of this study was to investigate, using eye-tracking
              technique, the influence of bottom-up and top-down processes on
              visual behavior while subjects, na{\"\i}ve to art criticism, were
              presented with representational paintings. Forty-two subjects
              viewed color and black and white paintings (Color) categorized as
              dynamic or static (Dynamism) (bottom-up processes). Half of the
              images represented natural environments and half human subjects
              (Content); all stimuli were displayed under aesthetic and
              movement judgment conditions (Task) (top-down processes). Results
              on gazing behavior showed that content-related top-down processes
              prevailed over low-level visually-driven bottom-up processes when
              a human subject is represented in the painting. On the contrary,
              bottom-up processes, mediated by low-level visual features,
              particularly affected gazing behavior when looking at
              nature-content images. We discuss our results proposing a
              reconsideration of the definition of content-related top-down
              processes in accordance with the concept of embodied simulation
              in art perception.",
  journal  = "PLoS One",
  volume   =  7,
  number   =  5,
  pages    = "e37285",
  month    =  may,
  year     =  2012,
  language = "en"
}

@inproceedings{Hutt2016TheEH,
  title={The Eyes Have It: Gaze-based Detection of Mind Wandering during Learning with an Intelligent Tutoring System},
  author={Stephen Hutt and Caitlin Mills and Shelby White and Patrick J. Donnelly and Sidney K. D’Mello},
  booktitle={EDM},
  year={2016}
}

  @inproceedings{guler2018densepose,
  title={Densepose: Dense human pose estimation in the wild},
  author={ G{\"u}ler, R{\i}za Alp and Neverova, Natalia and Kokkinos, Iasonas},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={7297--7306},
  year={2018}
}

@INPROCEEDINGS{9053659,

  author={Yang, Dawei and Li, Xinlei and Dai, Xiaotian and Zhang, Rui and Qi, Lizhe and Zhang, Wenqiang and Jiang, Zhe},

  booktitle={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 

  title={All In One Network for Driver Attention Monitoring}, 

  year={2020},

  volume={},

  number={},

  pages={2258-2262},

  doi={10.1109/ICASSP40776.2020.9053659}}

@misc{https://doi.org/10.48550/arxiv.2204.08096,
  doi = {10.48550/ARXIV.2204.08096},
  
  url = {https://arxiv.org/abs/2204.08096},
  
  author = {Rahman, Mohammed Shaiqur and Venkatachalapathy, Archana and Sharma, Anuj and Wang, Jiyang and Gursoy, Senem Velipasalar and Anastasiu, David and Wang, Shuo},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Synthetic Distracted Driving (SynDD1) dataset for analyzing distracted behaviors and various gaze zones of a driver},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@InProceedings{jOrtega2020, author="Ortega, Juan Diego and Kose, Neslihan and Cañas, Paola and Chao, Min-An and Unnervik, Alexander and Nieto, Marcos and Otaegui, Oihana and Salgado, Luis", editor="Bartoli, Adrien and Fusiello, Andrea", title="DMD: A Large-Scale Multi-modal Driver Monitoring Dataset for Attention and Alertness Analysis", booktitle="Computer Vision -- ECCV 2020 Workshops", year="2020", publisher="Springer International Publishing", pages="387--405", isbn="978-3-030-66823-5", doi="10.1007/978-3-030-66823-5_23"}

@misc{https://doi.org/10.48550/arxiv.2203.03339,
  doi = {10.48550/ARXIV.2203.03339},
  
  url = {https://arxiv.org/abs/2203.03339},
  
  author = {Abdelrahman, Ahmed A. and Hempel, Thorsten and Khalifa, Aly and Al-Hamadi, Ayoub},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {L2CS-Net: Fine-Grained Gaze Estimation in Unconstrained Environments},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@INPROCEEDINGS{7299081,  author={Zhang, Xucong and Sugano, Yusuke and Fritz, Mario and Bulling, Andreas},  booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},   title={Appearance-based gaze estimation in the wild},   year={2015},  volume={},  number={},  pages={4511-4520},  doi={10.1109/CVPR.2015.7299081}}

@inproceedings{eyelid_aperture,
author = {Ortega, Juan and Nieto, Marcos and Salgado, Luis and Otaegui, Oihana},
year = {2020},
month = {01},
pages = {342-352},
title = {User-adaptive Eyelid Aperture Estimation for Blink Detection in Driver Monitoring Systems},
doi = {10.5220/0009369003420352}
}